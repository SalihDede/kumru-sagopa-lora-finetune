# RunPod Serverless Deployment Guide

Bu dokÃ¼man, Sagopa Chatbot modelini RunPod serverless ortamÄ±na deploy etmek iÃ§in gereken adÄ±mlarÄ± aÃ§Ä±klar.

## ğŸš¨ Ã–nemli: Model DosyalarÄ±nÄ± Hugging Face'e YÃ¼kleyin

GitHub'Ä±n dosya boyutu limiti nedeniyle (2GB), model dosyalarÄ±nÄ±zÄ± Hugging Face Hub'a yÃ¼klemeniz gerekiyor.

### Model YÃ¼kleme AdÄ±mlarÄ±

1. **Hugging Face hesabÄ± oluÅŸturun**: [huggingface.co](https://huggingface.co)

2. **Access Token oluÅŸturun**:
   - Settings â†’ Access Tokens â†’ New token
   - "Write" yetkisi verin

3. **Model yÃ¼kleyin**:
```bash
# Gerekli paketi yÃ¼kleyin
pip install huggingface_hub

# Login yapÄ±n
huggingface-cli login
# Token'Ä±nÄ±zÄ± yapÄ±ÅŸtÄ±rÄ±n

# Model yÃ¼kleme scriptini Ã§alÄ±ÅŸtÄ±rÄ±n
python upload_to_huggingface.py
```

Script `SalihDede/kumru-sagopa-merged` adÄ±nda bir repo oluÅŸturacak ve modelinizi yÃ¼kleyecek.

**Alternatif**: Manuel yÃ¼kleme:
```python
from huggingface_hub import HfApi
api = HfApi()
api.upload_folder(
    folder_path="./SagoChatBOTAPI/kumru-sagopa-merged",
    repo_id="SalihDede/kumru-sagopa-merged",
    repo_type="model",
)
```

## Kurulum AdÄ±mlarÄ±

### 1. GitHub Secrets Ayarlama

GitHub reponuzda ÅŸu secrets'larÄ± ekleyin:
- `Settings` â†’ `Secrets and variables` â†’ `Actions` â†’ `New repository secret`

Gerekli secrets:
```
DOCKER_USERNAME: Docker Hub kullanÄ±cÄ± adÄ±nÄ±z
DOCKER_PASSWORD: Docker Hub ÅŸifreniz veya access token
```

### 2. GitHub'a Push

Model dosyalarÄ± artÄ±k GitHub'da deÄŸil, Hugging Face'de olacak:

```bash
# Git durumunu kontrol edin
git status

# Sadece kod dosyalarÄ±nÄ± ekleyin (model dosyalarÄ± HARÄ°Ã‡)
git add .dockerignore .github/ Dockerfile RUNPOD_DEPLOYMENT.md handler.py requirements.txt test_handler.py upload_to_huggingface.py .gitignore

# Commit yapÄ±n
git commit -m "Add RunPod serverless configuration (model on HuggingFace)

Co-Authored-By: Claude Sonnet 4.5 <noreply@anthropic.com>"

# Push edin
git push origin main
```

Push yaptÄ±ÄŸÄ±nÄ±zda GitHub Actions otomatik olarak:
- Docker imajÄ±nÄ± build edecek
- Docker Hub'a push edecek
- Model HuggingFace'den otomatik indirilecek

### 3. RunPod'da Serverless Endpoint OluÅŸturma

1. [RunPod Console](https://www.runpod.io/console/serverless) â†’ Serverless sekmesi
2. **"New Endpoint"** butonuna tÄ±klayÄ±n
3. AyarlarÄ± yapÄ±n:

   **Endpoint Configuration:**
   - **Name**: `sagopa-chatbot`
   - **Select Template**: Custom (Docker image)
   - **Container Image**: `<DOCKER_USERNAME>/sagopa-chatbot-runpod:latest`
   - **Container Disk**: 20 GB (model indirme iÃ§in yeterli alan)
   - **GPU Types**: GPU seÃ§in (Ã¶rn: RTX 4090, A4000, vb.)

   **Environment Variables (isteÄŸe baÄŸlÄ±):**
   - `MODEL_NAME`: `SalihDede/kumru-sagopa-merged` (farklÄ± bir model kullanÄ±yorsanÄ±z)
   - `HF_TOKEN`: Hugging Face token (private model iÃ§in gerekli)

   **Advanced Configuration:**
   - **Idle Timeout**: 5 seconds
   - **Execution Timeout**: 120 seconds (ilk yÃ¼kleme uzun sÃ¼rebilir)
   - **Min Workers**: 0
   - **Max Workers**: 3 (ihtiyacÄ±nÄ±za gÃ¶re)

4. **Deploy** butonuna tÄ±klayÄ±n

âš ï¸ **Not**: Ä°lk Ã§alÄ±ÅŸtÄ±rmada model Hugging Face'den indirilecek, bu 30-60 saniye sÃ¼rebilir. Sonraki istekler Ã§ok daha hÄ±zlÄ± olacak.

### 4. API Endpoint'i Test Etme

Endpoint oluÅŸturulduktan sonra bir API endpoint URL'i alacaksÄ±nÄ±z:
```
https://api.runpod.ai/v2/<ENDPOINT_ID>/runsync
```

Test iÃ§in curl kullanÄ±n:

```bash
curl -X POST "https://api.runpod.ai/v2/<ENDPOINT_ID>/runsync" \
  -H "Authorization: Bearer <RUNPOD_API_KEY>" \
  -H "Content-Type: application/json" \
  -d '{
    "input": {
      "prompt": "Merhaba Sagopa, nasÄ±lsÄ±n?",
      "max_new_tokens": 128,
      "temperature": 0.7
    }
  }'
```

### 5. Frontend Entegrasyonu

Portfolio sitenizde bu endpoint'i kullanmak iÃ§in Ã¶rnek JavaScript kodu:

```javascript
async function chatWithSagopa(userMessage, conversationHistory = []) {
  const response = await fetch('https://api.runpod.ai/v2/<ENDPOINT_ID>/runsync', {
    method: 'POST',
    headers: {
      'Authorization': 'Bearer YOUR_RUNPOD_API_KEY',
      'Content-Type': 'application/json'
    },
    body: JSON.stringify({
      input: {
        prompt: userMessage,
        messages: conversationHistory,
        max_new_tokens: 128,
        temperature: 0.7,
        do_sample: true
      }
    })
  });

  const data = await response.json();

  if (data.status === 'COMPLETED') {
    return {
      response: data.output.response,
      messages: data.output.messages
    };
  } else {
    throw new Error('Request failed: ' + data.status);
  }
}

// KullanÄ±m Ã¶rneÄŸi
const result = await chatWithSagopa("Merhaba Sagopa!");
console.log(result.response);
```

**âš ï¸ GÃœVENLÄ°K UYARISI**: Frontend'de direkt API key kullanmayÄ±n! Kendi backend'iniz Ã¼zerinden proxy yapÄ±n:

```javascript
// Frontend'den kendi backend'inize istek gÃ¶nderin
const response = await fetch('https://your-backend.com/api/chat', {
  method: 'POST',
  headers: {
    'Content-Type': 'application/json',
    'Authorization': 'Bearer USER_SESSION_TOKEN'  // Kendi auth sisteminiz
  },
  body: JSON.stringify({
    prompt: userMessage,
    messages: conversationHistory
  })
});

// Backend'inizde RunPod'a istek gÃ¶nderin
// Backend API key'i gÃ¼venli tutar
```

## API Input Format

Handler ÅŸu parametreleri kabul eder:

```json
{
  "input": {
    "prompt": "KullanÄ±cÄ± mesajÄ± (zorunlu)",
    "messages": [
      {"role": "user", "content": "Ã–nceki mesaj"},
      {"role": "assistant", "content": "Ã–nceki cevap"}
    ],
    "max_new_tokens": 128,
    "temperature": 0.7,
    "do_sample": true
  }
}
```

## API Output Format

BaÅŸarÄ±lÄ± response:
```json
{
  "delayTime": 1234,
  "executionTime": 5678,
  "id": "...",
  "status": "COMPLETED",
  "output": {
    "response": "Model cevabÄ±",
    "messages": [...],
    "status": "success"
  }
}
```

Hata durumunda:
```json
{
  "status": "FAILED",
  "output": {
    "error": "Hata mesajÄ±",
    "error_type": "ExceptionType",
    "status": "error"
  }
}
```

## Maliyet Optimizasyonu

1. **Idle Timeout**: DÃ¼ÅŸÃ¼k tutun (5-10 saniye) - kullanÄ±lmadÄ±ÄŸÄ±nda hÄ±zlÄ±ca kapanÄ±r
2. **Min Workers**: 0 yapÄ±n - hiÃ§ kullanÄ±lmadÄ±ÄŸÄ±nda Ã¼cret alÄ±nmaz
3. **Cold Start**: Ä°lk istek 30-60 saniye sÃ¼rebilir (model indirme), sonraki istekler 2-5 saniye
4. **GPU SeÃ§imi**:
   - **RTX 4090**: En hÄ±zlÄ±, biraz daha pahalÄ±
   - **A4000**: Ä°yi denge, Ã¶nerilen
   - **A5000**: Daha fazla VRAM gerekiyorsa
5. **Model Cache**: Container disk'i yeterli yapÄ±n (20GB+), model cache'lenir

## Proje Dosya YapÄ±sÄ±

```
.
â”œâ”€â”€ handler.py                      # RunPod serverless handler
â”œâ”€â”€ Dockerfile                      # Container konfigÃ¼rasyonu
â”œâ”€â”€ requirements.txt                # Python dependencies
â”œâ”€â”€ upload_to_huggingface.py       # Model yÃ¼kleme scripti
â”œâ”€â”€ test_handler.py                # Lokal test scripti
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ deploy-runpod.yml      # CI/CD pipeline
â”œâ”€â”€ .dockerignore                   # Docker build optimizasyonu
â””â”€â”€ SagoChatBOTAPI/
    â””â”€â”€ kumru-sagopa-merged/       # (Sadece lokal, Git'e gitmiyor)
```

## GÃ¼venlik NotlarÄ±

1. **API Key'i gizleyin**:
   - Frontend'de ASLA direkt RunPod API key kullanmayÄ±n
   - Kendi backend'iniz Ã¼zerinden proxy yapÄ±n

2. **Backend Proxy Ã–rneÄŸi** (Node.js/Express):
```javascript
app.post('/api/chat', authenticateUser, async (req, res) => {
  // KullanÄ±cÄ± auth kontrolÃ¼
  if (!req.user) return res.status(401).json({ error: 'Unauthorized' });

  // Rate limiting
  const rateLimit = await checkUserRateLimit(req.user.id);
  if (!rateLimit.allowed) {
    return res.status(429).json({ error: 'Too many requests' });
  }

  // RunPod'a istek gÃ¶nder
  const response = await fetch(RUNPOD_ENDPOINT, {
    method: 'POST',
    headers: {
      'Authorization': `Bearer ${process.env.RUNPOD_API_KEY}`,
      'Content-Type': 'application/json'
    },
    body: JSON.stringify({
      input: {
        prompt: req.body.prompt,
        messages: req.body.messages,
        max_new_tokens: 128
      }
    })
  });

  const data = await response.json();
  res.json(data);
});
```

3. **Rate Limiting**: AÅŸÄ±rÄ± kullanÄ±mÄ± engellemek iÃ§in:
   - KullanÄ±cÄ± baÅŸÄ±na gÃ¼nlÃ¼k/saatlik limit
   - IP bazlÄ± rate limiting
   - Mesaj uzunluÄŸu limiti

4. **Private Model**: Model'i private yapmak iÃ§in:
   - Hugging Face'de model'i private yapÄ±n
   - RunPod environment variable olarak `HF_TOKEN` ekleyin

## Troubleshooting

### Model yÃ¼klenemiyor
```
Error: Repository not found
```
**Ã‡Ã¶zÃ¼m**:
- Model'in Hugging Face'e yÃ¼klendiÄŸinden emin olun
- Private model iÃ§in `HF_TOKEN` environment variable ekleyin
- Model adÄ±nÄ±n doÄŸru olduÄŸunu kontrol edin (handler.py'de `MODEL_NAME`)

### Cold start Ã§ok uzun
```
Request timeout after 60s
```
**Ã‡Ã¶zÃ¼m**:
- Execution timeout'u 120 saniyeye Ã§Ä±karÄ±n (ilk yÃ¼kleme iÃ§in)
- Daha hÄ±zlÄ± internet baÄŸlantÄ±sÄ± olan bÃ¶lge seÃ§in
- Model quantization dÃ¼ÅŸÃ¼nÃ¼n (4-bit, 8-bit)

### Out of Memory
```
CUDA out of memory
```
**Ã‡Ã¶zÃ¼m**:
- Daha fazla VRAM'li GPU seÃ§in (RTX 4090: 24GB, A5000: 24GB)
- Model quantization kullanÄ±n
- `max_new_tokens` deÄŸerini dÃ¼ÅŸÃ¼rÃ¼n

### Container build failed
```
Failed to build Docker image
```
**Ã‡Ã¶zÃ¼m**:
- GitHub Actions logs'larÄ± kontrol edin
- Docker Hub'a login olduÄŸunuzdan emin olun
- `DOCKER_USERNAME` ve `DOCKER_PASSWORD` secrets'larÄ±n doÄŸru olduÄŸunu kontrol edin

### Model download failed during build
Model build sÄ±rasÄ±nda indirilemezse:
- Sorun deÄŸil! Model runtime'da indirilecek
- Ä°lk API isteÄŸi biraz daha uzun sÃ¼rer (30-60 saniye)
- Sonraki istekler normal hÄ±zda Ã§alÄ±ÅŸÄ±r

## GÃ¼ncelleme

Kodda deÄŸiÅŸiklik yaptÄ±ÄŸÄ±nÄ±zda:

```bash
git add .
git commit -m "Update handler configuration"
git push origin main
```

GitHub Actions yeni image'Ä± build edecek. RunPod otomatik olarak yeni image'Ä± kullanacaktÄ±r.

Model gÃ¼ncellemek iÃ§in:
1. Yeni modeli Hugging Face'e yÃ¼kleyin
2. `MODEL_NAME` environment variable'Ä±nÄ± gÃ¼ncelleyin (RunPod endpoint'te)
3. Endpoint'i yeniden baÅŸlatÄ±n

## Lokal Test

Deploy etmeden Ã¶nce lokal test yapabilirsiniz:

```bash
# Model'in lokal olduÄŸundan emin olun
ls SagoChatBOTAPI/kumru-sagopa-merged/

# Test script'i Ã§alÄ±ÅŸtÄ±rÄ±n
python test_handler.py
```

## Destek ve Kaynaklar

- [RunPod Documentation](https://docs.runpod.io/serverless/overview)
- [RunPod Discord](https://discord.gg/runpod)
- [Hugging Face Hub Docs](https://huggingface.co/docs/hub/index)
- [Transformers Documentation](https://huggingface.co/docs/transformers)

## Ã–zet: Deployment Checklist

- [ ] Model'i Hugging Face'e yÃ¼kleyin (`upload_to_huggingface.py`)
- [ ] GitHub Secrets'larÄ± ekleyin (`DOCKER_USERNAME`, `DOCKER_PASSWORD`)
- [ ] Kodu GitHub'a push edin (model dosyalarÄ± HARÄ°Ã‡)
- [ ] GitHub Actions'Ä±n Docker build etmesini bekleyin
- [ ] RunPod'da endpoint oluÅŸturun
- [ ] API'yi test edin
- [ ] Frontend'e entegre edin (backend proxy ile)
- [ ] Rate limiting ve gÃ¼venlik ekleyin
- [ ] Production'a deploy edin! ğŸš€
